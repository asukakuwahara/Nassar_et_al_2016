{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/asukakuwahara/Nassar_et_al_2016/blob/handson-exercise/Group_4_Nassar_2016_Hands_On.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "mz5v5Cabsh2L"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "from scipy import stats\n",
        "import pandas as pd\n",
        "from scipy.ndimage import gaussian_filter1d"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OX3Gxt2OzimS"
      },
      "source": [
        "# Group 4: Hands-on Exercise âœˆï¸ðŸ’°ðŸª¨\n",
        "\n",
        "Hey everyone! Welcome to our code walkthrough of the Nassar et al. (2016) paper on age differences in learning.\n",
        "\n",
        "**Big shoutout to Group 3!** Their tutorial was excellent and served as the foundation for our work here. We've built on their approach and extended it with additional models and visualizations.\n",
        "\n",
        "### Table of contents\n",
        "- Model Specification\n",
        "- Generate the Helicopter Task Environment\n",
        "- Normative Base Model\n",
        "- Plot the Normative Model\n",
        "-  Flexible Models\n",
        "    - Flexible No. 1: Uncertainty Underestimators\n",
        "    - Flexible No. 2: Surprise Insensitivity\n",
        "    - Flexible No. 3: Low hazard rate\n",
        "- Learning Rate Trajectories Compared to the Normative Model\n",
        "- A New Environment (Oddball environment!)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o9P8xVpF124Y"
      },
      "source": [
        "# Model Specification\n",
        "\n",
        "Before we run any code, let's get the equations straight.\n",
        "Don't worry - each one does something simple!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6dfRQYEcEa5K"
      },
      "source": [
        "### Tests\n",
        "Please ignore this tests for now. If you want to try out some other values go ahead."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "kVzvaJD47HE9"
      },
      "outputs": [],
      "source": [
        "# Unit tests for each spec function\n",
        "\n",
        "import math\n",
        "\n",
        "def test_predictive_variance(predictive_variance):\n",
        "\n",
        "    # Case 1: Omega = 0 â†’ reduces to sigma_N^2 * tau\n",
        "    sigma_N = 10\n",
        "    tau_t = 0.5\n",
        "    Omega_t = 0\n",
        "    delta_t = 50\n",
        "    expected = sigma_N**2 * tau_t\n",
        "    assert math.isclose(\n",
        "        predictive_variance(Omega_t, sigma_N, tau_t, delta_t),\n",
        "        expected\n",
        "    )\n",
        "\n",
        "    # Case 2: tau = 1 â†’ predictive variance = sigma_N^2\n",
        "    assert math.isclose(\n",
        "        predictive_variance(Omega_t=0.7, sigma_N=10, tau_t=1, delta_t=999),\n",
        "        10**2\n",
        "    )\n",
        "\n",
        "    # Case 3: non-negativity\n",
        "    pv = predictive_variance(0.3, 10, 0.4, -20)\n",
        "    assert pv >= 0\n",
        "\n",
        "    # Case 4: Increasing sigma_N increases predictive variance\n",
        "    pv_small_noise = predictive_variance(0.3, 10, 0.2, 10)\n",
        "    pv_big_noise   = predictive_variance(0.3, 20, 0.2, 10)\n",
        "    assert pv_big_noise > pv_small_noise\n",
        "\n",
        "    # Case 5: Check that delta affects predictive variance directionally\n",
        "    pv_zero = predictive_variance(0.5, 10, 0.5, 0)\n",
        "    pv_pos  = predictive_variance(0.5, 10, 0.5, 20)\n",
        "    pv_neg  = predictive_variance(0.5, 10, 0.5, -20)\n",
        "\n",
        "    assert pv_pos  != pv_zero\n",
        "    assert pv_neg  != pv_zero\n",
        "\n",
        "    print(\"All predictive_variance tests passed! ðŸŽ‰\")\n",
        "\n",
        "\n",
        "def test_relative_uncertainty(relative_uncertainty):\n",
        "    # Test 1: symmetric values â†’ Ï„ = 0.5\n",
        "    assert math.isclose(relative_uncertainty(10, 10), 0.5)\n",
        "\n",
        "    # Test 2: Ïƒ_Î¼ >> Ïƒ_N â†’ Ï„ approaches 1\n",
        "    assert relative_uncertainty(1000, 1) > 0.999\n",
        "\n",
        "    # Test 3: Ïƒ_Î¼ << Ïƒ_N â†’ Ï„ approaches 0\n",
        "    assert relative_uncertainty(1, 1000) < 0.001\n",
        "\n",
        "    # Test 4: Ïƒ_Î¼ = 0 â†’ Ï„ = 0\n",
        "    assert relative_uncertainty(0, 10) == 0\n",
        "\n",
        "    # Test 5: Ïƒ_N = 0 â†’ Ï„ = 1 (all uncertainty from Ïƒ_Î¼)\n",
        "    assert relative_uncertainty(10, 0) == 1\n",
        "\n",
        "    # Test 6: monotonicity: increasing Ïƒ_Î¼ should increase Ï„\n",
        "    tau_low = relative_uncertainty(5, 20)\n",
        "    tau_high = relative_uncertainty(10, 20)\n",
        "    assert tau_high > tau_low\n",
        "\n",
        "    print(\"All relative uncertainty tests passed! ðŸŽ‰\")\n",
        "\n",
        "def test_standard_deviation_squared(standard_deviation_squared):\n",
        "    # Basic correctness\n",
        "    assert standard_deviation_squared(10) == 100\n",
        "\n",
        "    # Zero case\n",
        "    assert standard_deviation_squared(0) == 0\n",
        "\n",
        "    # Monotonicity\n",
        "    assert standard_deviation_squared(20) > standard_deviation_squared(10)\n",
        "\n",
        "    print(\"All standard_deviation_squared tests passed! ðŸŽ‰\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKqCG0EH8C4U"
      },
      "source": [
        "## Prediction error\n",
        "\n",
        "$\\delta_t = X_t - B_t$\n",
        "\n",
        "Trial outcomes and participant bucket placements determined the prediction error (and consequently, surprise magnitide).\n",
        "\n",
        "$X_t$ is our outcome and $B_t$ is our bucket placement."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "cgKpjsKA8D9w"
      },
      "outputs": [],
      "source": [
        "def prediction_error(X_t, B_t):\n",
        "    return X_t - B_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VR0LbuCb5Ltg"
      },
      "source": [
        "## Relative Uncertainty\n",
        "\n",
        "$$\n",
        "\\tau_{t+1} = \\frac{\\sigma_\\mu^2}{\\sigma_\\mu^2 + \\sigma_N^2}\n",
        "$$\n",
        "\n",
        "\n",
        "Where:\n",
        "- $\\sigma_\\mu^2$ is the variance of the predicted distribution over posisble helicopter locations\n",
        "- $\\sigma_N^2$ is the variance of the distribution over noise (possible bag distributions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tzYXpgjs9jvN"
      },
      "source": [
        "### ðŸ§ ðŸ§ ðŸ§  Exercise 1: Fill in the code to get the correct value!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "YNfamsNN5ZaF"
      },
      "outputs": [],
      "source": [
        "def relative_uncertainty(sig_mu,sig_N):\n",
        "    return #YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 277
        },
        "id": "RhyYMwHe7tgV",
        "outputId": "3eb0d36c-127e-4839-93e2-17bded9c6ee3"
      },
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "must be real number, not NoneType",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-2679498858.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_relative_uncertainty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelative_uncertainty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-3415233340.py\u001b[0m in \u001b[0;36mtest_relative_uncertainty\u001b[0;34m(relative_uncertainty)\u001b[0m\n\u001b[1;32m     44\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mtest_relative_uncertainty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelative_uncertainty\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     45\u001b[0m     \u001b[0;31m# Test 1: symmetric values â†’ Ï„ = 0.5\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 46\u001b[0;31m     \u001b[0;32massert\u001b[0m \u001b[0mmath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrelative_uncertainty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     48\u001b[0m     \u001b[0;31m# Test 2: Ïƒ_Î¼ >> Ïƒ_N â†’ Ï„ approaches 1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: must be real number, not NoneType"
          ]
        }
      ],
      "source": [
        "test_relative_uncertainty(relative_uncertainty)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N0h-Uz-D7RF9"
      },
      "source": [
        "$\\sigma_\\mu^2$ is the variance on the predictive distribution over possible helicopter locations:\n",
        "\n",
        "$$\\sigma_{\\mu}^2 = \\Omega_t \\sigma_N^2 + (1 - \\Omega_t)\\sigma_N^2 \\tau_t + \\Omega_t(1 - \\Omega_t)\\delta_t(1 - \\tau_t)$$\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Vun6zQfBbVK"
      },
      "source": [
        "### ðŸ§ ðŸ§ ðŸ§  Exercise 2: Fill in the code to get the correct value!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xp-EMx7_7QxX"
      },
      "outputs": [],
      "source": [
        "def predictive_variance(Omega_t, sigma_N, tau_t, delta_t):\n",
        "    sigma_mu_sq = #YOUR CODE HERE\n",
        "    return sigma_mu_sq"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yUso0dZP7y7d"
      },
      "outputs": [],
      "source": [
        "test_predictive_variance(predictive_variance)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qaWaNBjW7H58"
      },
      "source": [
        "$\\sigma_N^2$ is the variance of the noise distribution based on the standard deviation we set. Standard deviation for low noise is set to 10 and high noise is set to 25.\n",
        "\n",
        "$$ÏƒNâˆˆ10,25$$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZZAu8CF-BeSO"
      },
      "source": [
        "### ðŸ§ ðŸ§ ðŸ§  Exercise 3: Fill in the code to get the correct value!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p1zMaUv55lYJ"
      },
      "outputs": [],
      "source": [
        "def standard_deviation_squared(noise_std):\n",
        "    return #YOUR CODE HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hR_cCu6l9Piy"
      },
      "outputs": [],
      "source": [
        "test_standard_deviation_squared(standard_deviation_squared)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4hK8MQ4CwCY1"
      },
      "source": [
        "## Change Point Probability\n",
        "\n",
        "$$\n",
        "\\Omega_{t+1} = \\frac{H / 300}{H / 300 + \\mathcal{N}^\\sim \\left( \\delta_{t+1} \\mid 0, \\frac{\\sigma_N^2}{1 - \\tau_{t+1}} \\right) (1 - H)}\n",
        "$$\n",
        "\n",
        "Where:\n",
        "- $H$: Hazard rate (prior probability of change point)\n",
        "- $\\mathcal{N}(\\delta|0, \\sigma^2)$: Normal probability density function evaluated at prediction error $\\delta$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ie142L7txc81"
      },
      "source": [
        "$H$ is hazard rate (Prior Change Point Probability)\n",
        "$$p(cp)=H$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZI-3BdglwmG3"
      },
      "outputs": [],
      "source": [
        "def prior_CP(H):\n",
        "    return H"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPf9youCzbVa"
      },
      "source": [
        "$\\mathcal{N}(\\delta|0, \\sigma^2)$ is normal probability density function evaluated at prediction error $\\delta$\n",
        "\n",
        "$$\n",
        "{\\mathcal{N}^\\sim \\left( \\delta_{t+1} \\mid 0, \\frac{\\sigma_N^2}{1 - \\tau_{t+1}} \\right)}\n",
        "$$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ix5S3RaLx7TF"
      },
      "outputs": [],
      "source": [
        "def probability_normal(delta_t1, sigma_N, tau_t1):\n",
        "    sigma = np.sqrt(sigma_N**2 / (1 - tau_t1))\n",
        "    return stats.norm.pdf(delta_t1, loc=0, scale=sigma)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sHR-lAsFyuZW"
      },
      "source": [
        "Change Point Probability\n",
        "\n",
        "$$\n",
        "\\Omega_{t+1} = \\frac{H / 300}{H / 300 + \\mathcal{N}^\\sim \\left( \\delta_{t+1} \\mid 0, \\frac{\\sigma_N^2}{1 - \\tau_{t+1}} \\right) (1 - H)}\n",
        "$$\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bZMgs8749m5e"
      },
      "outputs": [],
      "source": [
        "def probability_change_point_new(H, delta_t1, sigma_N, tau_t1):\n",
        "    num = prior_CP(H) / 300.0\n",
        "    den = num + probability_normal(delta_t1, sigma_N, tau_t1)*(1 - H)\n",
        "    return num / den"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WypMotj6MW3v"
      },
      "source": [
        "The recursive computation serves as a normative model designed to dynamically adjust learning rates on each trial, optimizing inference in a dynamic environment.\n",
        "\n",
        "1. **Calculate Predictive Variance (`Ïƒ_mu^2`)**  \n",
        "   In other words, we calculate the raw estimation uncertainty about the location of the helicopter based on the previous trial variable values of CPP, relative uncertainty, and prediction error (surprise).\n",
        "  2. **Compute Relative Uncertainty (`Ï„_{t+1}`)**  \n",
        "   `Ïƒ_mu^2` is then used to calculate relative uncertainty, which now takes into account the uncertainty that is inherent to the environment (the ground-truch environmental noise).\n",
        "   3. **Calibrate Change-Point Probability (`Î©_{t+1}`)**  \n",
        "   CPP is calculated using our relative uncertainty, and ground-truth environmental noise, and prediction error. The value of CPP is highly contingent on the level of surprise. The larger the surprise, the larger the (subjective) measure of change-point probability is.\n",
        "\n",
        "These subjective measures are used to update the learning rate."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JLfaPJeT8LU8"
      },
      "source": [
        "## Learning rate\n",
        "\n",
        "$Î±_t = Î©_t+Ï„_t*(1-Î©)$\n",
        "\n",
        "Where:\n",
        "- $\\Omega_t$: Change-point probability\n",
        "- $\\tau_t$: Uncertainty\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "A_KFqk_H8OOC"
      },
      "outputs": [],
      "source": [
        "def learning_rate(omega_t1, tau_t1):\n",
        "    return omega_t1 + (1 - omega_t1) * tau_t1"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "I7Pfr0zE8TFu"
      },
      "source": [
        "## Estimated Mean (Delta Rule)\n",
        "\n",
        "$B_{t+1} = B_t + Î±_t * Î´_t$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MWyzvMQ8OuV"
      },
      "outputs": [],
      "source": [
        "def update_belief(B_t, alpha_t1, delta_t):\n",
        "    return B_t + alpha_t1 * delta_t"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bcBo12OoARYU"
      },
      "source": [
        "## Exercise sample solutions: (In case you're stuck!)\n",
        "<details>\n",
        "  <summary>Sample solutions</summary>\n",
        "\n",
        "  <pre>\n",
        "    <code>\n",
        "def relative_uncertainty(sig_mu,sig_N):\n",
        "    return sig_mu**2 / (sig_mu**2 + sig_N**2)\n",
        "\n",
        "def predictive_variance(Omega_t, sigma_N, tau_t, delta_t):\n",
        "    sigma_mu_sq = (\n",
        "        Omega_t * (sigma_N ** 2)\n",
        "        + (1 - Omega_t) * (sigma_N ** 2) * tau_t\n",
        "        + Omega_t * (1 - Omega_t) * delta_t * (1 - tau_t))\n",
        "    return sigma_mu_sq\n",
        "\n",
        "def standard_deviation_squared(noise_std):\n",
        "    return noise_std**2\n",
        "    </code>\n",
        "  </pre>\n",
        "\n",
        "</details>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FMX875w7LmiS"
      },
      "source": [
        "# Generate the task environment\n",
        "### Let's all work with the same deterministic environment.\n",
        "\n",
        "We need to create a simulated version of the task that participants experienced.\n",
        "\n",
        "Please don't change the seed -- we'll need to compare answers later on in the tutorial!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GIo3gCXkLuSt"
      },
      "outputs": [],
      "source": [
        "def generate_environment(n_trials=400, H=0.1, sigma_low=10, sigma_high=25):\n",
        "    \"\"\"\n",
        "    Generate helicopter (true) and bag (observed) positions for 400 trials:\n",
        "    - First 200 trials: low noise\n",
        "    - Last 200 trials: high noise\n",
        "    Hazard rate H is fixed for all trials.\n",
        "    Range of positions: 0-300\n",
        "    \"\"\"\n",
        "    np.random.seed(42)  # reproducibility\n",
        "\n",
        "    block_length = n_trials // 2\n",
        "    sigma_sequence = np.concatenate([\n",
        "        np.full(block_length, sigma_low),\n",
        "        np.full(block_length, sigma_high)\n",
        "    ])\n",
        "\n",
        "    mu = np.zeros(n_trials)  # true helicopter position\n",
        "    X = np.zeros(n_trials)   # observed bag drops\n",
        "\n",
        "    # Initialize helicopter randomly\n",
        "    mu[0] = np.random.uniform(0, 300)\n",
        "    X[0] = np.random.normal(mu[0], sigma_sequence[0])\n",
        "\n",
        "    # Generate trials\n",
        "    for t in range(1, n_trials):\n",
        "        # Change-point decision\n",
        "        if np.random.rand() < H:\n",
        "            mu[t] = np.random.uniform(0, 300)\n",
        "        else:\n",
        "            mu[t] = mu[t - 1]\n",
        "\n",
        "        # Bag drop with current noise\n",
        "        X[t] = np.random.normal(mu[t], sigma_sequence[t])\n",
        "    return mu, X, sigma_sequence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SA10Hlr5MD33"
      },
      "outputs": [],
      "source": [
        "mu, X, sigma_seq = generate_environment()\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(10,4))\n",
        "plt.plot(mu, label='True Helicopter (Î¼)', linewidth=2)\n",
        "plt.scatter(range(len(X)), X, s=10, alpha=0.5, label='Bag Drops (X)')\n",
        "plt.axvline(200, color='red', linestyle='--', label='Noise switch')\n",
        "plt.title('Simulated Environment: Low Noise â†’ High Noise')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('Position')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3W0YJWk9Lynm"
      },
      "source": [
        "# Normative Model\n",
        "\n",
        "### Now, let's build our normative base model!\n",
        "Combine the model specification together and build our model!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "a9af7d15"
      },
      "source": [
        "### `NormativeBaseModel` Class Parameters\n",
        "\n",
        "This class simulates a learning model based on Nassar et al. (2016) and its variations. Below are the parameters used during initialization:\n",
        "\n",
        "| Parameter          | Description                                                                 | Default Value |\n",
        "| :----------------- | :-------------------------------------------------------------------------- | :------------ |\n",
        "| `X`                | Array of observed bag drop positions (trial outcomes).                      | _None_        |\n",
        "| `sigma_sequence`   | Array specifying the noise standard deviation for each trial.               | _None_        |\n",
        "| `H`                | Hazard rate, representing the prior probability of a change point.          | `0.1`         |\n",
        "| `uncertainty_scale`| Multiplier applied to predictive variance to simulate underestimation/overestimation of uncertainty. | `1.0`         |\n",
        "| `surprise_sensitivity`| Exponent applied to the likelihood in change-point probability calculation to model sensitivity to surprise. | `1.0`         |\n",
        "|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BhOuwp5p_c1W"
      },
      "outputs": [],
      "source": [
        "class NormativeBaseModel:\n",
        "    \"\"\"\n",
        "    Base class for Nassar et al. (2016) models\n",
        "    \"\"\"\n",
        "    def __init__(self, X, sigma_sequence, H=0.1,\n",
        "                 uncertainty_scale=1.0, surprise_sensitivity=1.0):\n",
        "        # Store inputs\n",
        "        self.X = X\n",
        "        self.sigma_sequence = sigma_sequence\n",
        "        self.n_trials = len(X)\n",
        "\n",
        "        # Model parameters\n",
        "        self.hazard_rate = H\n",
        "        self.uncertainty_scale = uncertainty_scale\n",
        "        self.surprise_sensitivity = surprise_sensitivity\n",
        "\n",
        "        # Initial belief\n",
        "        self.initial_belief = X[0]\n",
        "        self.belief = X[0]\n",
        "\n",
        "        # Get noise from first trial (will update per trial)\n",
        "        self.sigma_n = sigma_sequence[0]\n",
        "        self.sigma_n_squared = sigma_sequence[0] ** 2\n",
        "\n",
        "        # State variables\n",
        "        self.sigma_mu_squared = self.sigma_n_squared\n",
        "        self.tau = 0.1  # Match your initial tau\n",
        "        self.alpha = 0.3\n",
        "\n",
        "        # History tracking\n",
        "        self.history = {\n",
        "            'beliefs': [],\n",
        "            'prediction_errors': [],\n",
        "            'learning_rates': [],\n",
        "            'uncertainties': [],\n",
        "            'change_point_probs': []\n",
        "        }\n",
        "\n",
        "    def update(self, t):\n",
        "        \"\"\"\n",
        "        Update belief for trial t\n",
        "        \"\"\"\n",
        "\n",
        "        # Get current trial's noise level\n",
        "        self.sigma_n = self.sigma_sequence[t]\n",
        "        self.sigma_n_squared = self.sigma_sequence[t] ** 2\n",
        "\n",
        "        # 1. Prediction error\n",
        "        delta = prediction_error(self.X[t], self.belief)\n",
        "\n",
        "        # 2. Change-point probability (with surprise sensitivity)\n",
        "        omega = self._compute_change_point_prob(delta)\n",
        "\n",
        "        # 3. Predictive variance\n",
        "        sig_mu_sq = predictive_variance(omega, self.sigma_n, self.tau, delta)\n",
        "\n",
        "\n",
        "        # 4. Update uncertainty\n",
        "        # Estimation uncertainty divided by uncertainty scale\n",
        "        sig_mu_sq /= self.uncertainty_scale\n",
        "        # Update relative uncertainty\n",
        "        self.tau = relative_uncertainty(np.sqrt(sig_mu_sq), self.sigma_n)\n",
        "\n",
        "        # 5. Learning rate\n",
        "        self.alpha = learning_rate(omega, self.tau)\n",
        "\n",
        "        # 6. Update belief\n",
        "        self.belief = update_belief(self.belief, self.alpha, delta)\n",
        "        self.belief = np.clip(self.belief, 0, 300)\n",
        "\n",
        "        # 7. Store history\n",
        "        self._store_history(delta, omega)\n",
        "\n",
        "        return self.belief\n",
        "\n",
        "    def _compute_change_point_prob(self, delta):\n",
        "        \"\"\"Compute change-point probability with surprise sensitivity\"\"\"\n",
        "        # Compute likelihood with surprise power\n",
        "        var_no_cp = self.sigma_n_squared / (1 - self.tau)\n",
        "        likelihood = stats.norm.pdf(delta, 0, np.sqrt(var_no_cp))\n",
        "        likelihood_powered = likelihood ** self.surprise_sensitivity\n",
        "\n",
        "        # Bayes rule\n",
        "        num = self.hazard_rate / (300.0 ** self.surprise_sensitivity)\n",
        "        den = num + likelihood_powered * (1 - self.hazard_rate)\n",
        "        omega = num / den\n",
        "\n",
        "        return np.clip(omega, 1e-6, 1 - 1e-6)\n",
        "\n",
        "    def _store_history(self, delta, omega):\n",
        "        \"\"\"Store trial results\"\"\"\n",
        "        self.history['beliefs'].append(self.belief)\n",
        "        self.history['prediction_errors'].append(delta)\n",
        "        self.history['learning_rates'].append(self.alpha)\n",
        "        self.history['uncertainties'].append(self.tau)\n",
        "        self.history['change_point_probs'].append(omega)\n",
        "\n",
        "    def run(self):\n",
        "        \"\"\"\n",
        "        Run model on full task sequence\n",
        "        Returns DataFrame compatible with function-based approach\n",
        "        \"\"\"\n",
        "        # Initialize with first trial\n",
        "        self.belief = self.X[0]\n",
        "        self.tau = 0.1\n",
        "\n",
        "        # Store first trial (no update, just initialization)\n",
        "        self.history['beliefs'].append(self.belief)\n",
        "        self.history['prediction_errors'].append(0.0)\n",
        "        self.history['learning_rates'].append(0.0)\n",
        "        self.history['uncertainties'].append(self.tau)\n",
        "        self.history['change_point_probs'].append(0.0)\n",
        "\n",
        "        # Run trials 1 through n_trials-1\n",
        "        for t in range(1, self.n_trials):\n",
        "            self.update(t)\n",
        "\n",
        "        # Create DataFrame (compatible with your existing code)\n",
        "        df = pd.DataFrame({\n",
        "            \"Trial\": np.arange(1, self.n_trials + 1),\n",
        "            \"TruePosition\": mu,\n",
        "            \"BagDrop\": self.X,\n",
        "            \"Belief\": self.history['beliefs'],\n",
        "            \"CPP\": self.history['change_point_probs'],\n",
        "            \"RelUncertainty\": self.history['uncertainties'],\n",
        "            \"LearningRate\": self.history['learning_rates'],\n",
        "            \"PredictionError\": self.history['prediction_errors']\n",
        "        })\n",
        "\n",
        "        return df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dtz7rKngPgmj"
      },
      "outputs": [],
      "source": [
        "# Normative parameters\n",
        "DEFAULT_H = 0.1\n",
        "DEFAULT_UNCERTAINTY_SCALE = 1.0\n",
        "DEFAULT_SURPRISE_SENSITIVITY = 1.0\n",
        "\n",
        "# Create the normative model by passing default parameters\n",
        "normative_model = NormativeBaseModel(X, sigma_seq, H=DEFAULT_H, uncertainty_scale=DEFAULT_UNCERTAINTY_SCALE, surprise_sensitivity=DEFAULT_SURPRISE_SENSITIVITY)\n",
        "normative_model_results = normative_model.run()\n",
        "display(normative_model_results)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tnsZ5RkdS3kS"
      },
      "source": [
        "# Plot the Normative Model (Optimal Behaviour in Response to our Determinisitc Environment)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uHrRL_4xVRCp"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "\n",
        "# Plot 1: Trial vs Screen Position\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(normative_model_results['Trial'], normative_model_results['TruePosition'], 'k--', label='True Helicopter')\n",
        "plt.plot(normative_model_results['Trial'], normative_model_results['Belief'], 'b-', label='Normative Model Belief')\n",
        "plt.axvspan(0, 200, color='green', alpha=0.1, label='Low Noise (Ïƒ=10)')\n",
        "plt.axvspan(200, 400, color='red', alpha=0.1, label='High Noise (Ïƒ=25)')\n",
        "plt.ylabel(\"Position (0-300)\")\n",
        "plt.title(\"Normative Model: Belief vs True Helicopter\")\n",
        "plt.legend()\n",
        "\n",
        "# Trial vs Model Estimates (Surprise, Uncertainty)\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(normative_model_results['Trial'], normative_model_results['PredictionError'], color='orange', label='Surprise (Î´)')\n",
        "plt.plot(normative_model_results['Trial'], normative_model_results['RelUncertainty'], color='purple', label='Relative Uncertainty (Ï„)')\n",
        "plt.axvspan(0, 200, color='green', alpha=0.1, label='Low Noise (Ïƒ=10)')\n",
        "plt.axvspan(200, 400, color='red', alpha=0.1, label='High Noise (Ïƒ=25)')\n",
        "plt.ylabel(\"Model Estimates\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.title(\"Normative Model: Surprise and Uncertaintyper Trial\")\n",
        "plt.legend()\n",
        "\n",
        "# Zoom-in\n",
        "zoom_start, zoom_end = 180, 220\n",
        "trials_zoom = normative_model_results['Trial'][zoom_start:zoom_end+1]\n",
        "\n",
        "# Normalize for visual clarity\n",
        "pred_error_zoom = np.abs(normative_model_results['PredictionError'][zoom_start:zoom_end+1])\n",
        "pred_error_norm = pred_error_zoom / np.max(pred_error_zoom)\n",
        "rel_unc_zoom = normative_model_results['RelUncertainty'][zoom_start:zoom_end+1]\n",
        "rel_unc_norm = rel_unc_zoom / np.max(rel_unc_zoom)\n",
        "\n",
        "plt.subplot(3,1,3)\n",
        "plt.plot(trials_zoom, pred_error_norm, color='orange', label='Surprise (Î´, normalized)')\n",
        "plt.plot(trials_zoom, rel_unc_norm, color='purple', label='Relative Uncertainty (Ï„, normalized)')\n",
        "plt.axvspan(180, 200, color='green', alpha=0.1, label='Low Noise')\n",
        "plt.axvspan(200, 220, color='red', alpha=0.1, label='High Noise')\n",
        "plt.ylabel(\"Normalized Values (0-1)\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.title(\"Zoom-in: Surprise and Relative Uncertainty (Trials 180-220)\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vl3Ui9AFGVFC"
      },
      "source": [
        "# Flexible Models\n",
        "\n",
        "3 flexible models listed in the paper take artificially manipulated parameters to reproduce the sub-optimal learnings."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pAVg9jT2txMs"
      },
      "source": [
        "# Flexible No. 1: Uncertainty Underestimators"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6gPw4cqfvHjC"
      },
      "source": [
        "This model artificially reduces estimated uncertainty on every trial by dividing the predictive variance (Ïƒ_Î¼Â²) by a constant (uncertainty_scale).\n",
        "\n",
        "For the simulation figures, Nassar et al. used 10.\n",
        "\n",
        "You may choose to use a different constant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "tSiiVO6yttvC"
      },
      "outputs": [],
      "source": [
        "uncertainty_underestimate = NormativeBaseModel(X, sigma_seq, uncertainty_scale=10)\n",
        "uncertainty_underestimate_results = uncertainty_underestimate.run()\n",
        "display(uncertainty_underestimate_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GoPuL5hNv95k"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "\n",
        "# Top plot: Belief vs True Helicopter\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(uncertainty_underestimate_results['Trial'], uncertainty_underestimate_results['TruePosition'], 'k--', label='True Helicopter')\n",
        "plt.plot(uncertainty_underestimate_results['Trial'], uncertainty_underestimate_results['Belief'], 'b-', label='Flexible Model Belief')\n",
        "plt.axvspan(0, 200, color='green', alpha=0.1, label='Low Noise (Ïƒ=10)')\n",
        "plt.axvspan(200, 400, color='red', alpha=0.1, label='High Noise (Ïƒ=25)')\n",
        "plt.ylabel(\"Position (0-300)\")\n",
        "plt.title(\"Uncertainty Underestimation: Belief vs True Helicopter\")\n",
        "plt.legend()\n",
        "\n",
        "# Middle plot: Prediction error & relative uncertainty\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(uncertainty_underestimate_results['Trial'], uncertainty_underestimate_results['PredictionError'], color='orange', label='Surprise (Î´)')\n",
        "plt.plot(uncertainty_underestimate_results['Trial'], uncertainty_underestimate_results['RelUncertainty'], color='purple', label='Relative Uncertainty (Ï„)')\n",
        "plt.ylabel(\"Model Estimates\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.title(\"Uncertainty Underestimation: Surprise and Relative Uncertainty\")\n",
        "plt.legend()\n",
        "\n",
        "# Bottom plot: Zoom-in (trials 180-220)\n",
        "zoom_start, zoom_end = 180, 220\n",
        "plt.subplot(3,1,3)\n",
        "# Normalize for visibility\n",
        "pred_zoom = np.abs(uncertainty_underestimate_results['PredictionError'][zoom_start:zoom_end+1])\n",
        "pred_zoom_norm = pred_zoom / np.max(pred_zoom)\n",
        "tau_zoom = uncertainty_underestimate_results['RelUncertainty'][zoom_start:zoom_end+1]\n",
        "tau_zoom_norm = tau_zoom / np.max(tau_zoom)\n",
        "trials_zoom = uncertainty_underestimate_results['Trial'][zoom_start:zoom_end+1]\n",
        "\n",
        "plt.plot(trials_zoom, pred_zoom_norm, color='orange', label='Surprise (Î´, normalized)')\n",
        "plt.plot(trials_zoom, tau_zoom_norm, color='purple', label='Relative Uncertainty (Ï„, normalized)')\n",
        "plt.axvspan(180, 200, color='green', alpha=0.1)\n",
        "plt.axvspan(200, 220, color='red', alpha=0.1)\n",
        "plt.ylabel(\"Normalized Values (0-1)\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.title(\"Zoom-in: Uncertainty Underestimation (Trials 180-220)\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9J2KyH_tuXUH"
      },
      "source": [
        "# Flexible No. 2: Surprise Insensitivity\n",
        "This model artificially manipulate Change point likelihood changed to aising the change point likelihood to a power between 0 and 1 by reducing surprise sensitivity.\n",
        "For the simulation figures, Nassar et al. used 0.2.\n",
        "\n",
        "You may choose to use a different constant."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hgGchne5zQtc"
      },
      "source": [
        "### ðŸ§ ðŸ§ ðŸ§  Exercise 4: Fill in the code to generate the surprise insensitive model!\n",
        "\n",
        "<details>\n",
        "<summary>hint:</summary>\n",
        "\n",
        "`NormativeBaseModel` Class Parameters\n",
        "\n",
        "This class simulates a learning model based on Nassar et al. (2016) and its variations. Below are the parameters used during initialization:\n",
        "\n",
        "| Parameter          | Description                                                                 | Default Value |\n",
        "| :----------------- | :-------------------------------------------------------------------------- | :------------ |\n",
        "| `X`                | Array of observed bag drop positions (trial outcomes).                      | _None_        |\n",
        "| `sigma_sequence`   | Array specifying the noise standard deviation for each trial.               | _None_        |\n",
        "| `H`                | Hazard rate, representing the prior probability of a change point.          | `0.1`         |\n",
        "| `uncertainty_scale`| Multiplier applied to predictive variance to simulate underestimation/overestimation of uncertainty. | `1.0`         |\n",
        "| `surprise_sensitivity`| Exponent applied to the likelihood in change-point probability calculation to model sensitivity to surprise. | `1.0`         |\n",
        "|\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "16tQPLJnulvk"
      },
      "outputs": [],
      "source": [
        "surprise_insensitive_model = NormativeBaseModel(#YOUR CODE HERE)\n",
        "surprise_insensitive_model_results = surprise_insensitive_model.run()\n",
        "display(surprise_insensitive_model_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "JVZyjKbqwamq"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "\n",
        "# Top plot: Belief vs True Helicopter\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(surprise_insensitive_model_results['Trial'], surprise_insensitive_model_results['TruePosition'], 'k--', label='True Helicopter')\n",
        "plt.plot(surprise_insensitive_model_results['Trial'], surprise_insensitive_model_results['Belief'], 'b-', label='Flexible Model Belief')\n",
        "plt.axvspan(0, 200, color='green', alpha=0.1)\n",
        "plt.axvspan(200, 400, color='red', alpha=0.1)\n",
        "plt.ylabel(\"Position (0-300)\")\n",
        "plt.title(\"Insensitivity to Surprise: Belief vs True Helicopter\")\n",
        "plt.legend()\n",
        "\n",
        "# Middle plot: Prediction error & relative uncertainty\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(surprise_insensitive_model_results['Trial'], surprise_insensitive_model_results['PredictionError'], color='orange', label='Surprise (Î´)')\n",
        "plt.plot(surprise_insensitive_model_results['Trial'], surprise_insensitive_model_results['RelUncertainty'], color='purple', label='Relative Uncertainty (Ï„)')\n",
        "plt.ylabel(\"Model Estimates\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.title(\"Insensitivity to Surprise: Surprise and Relative Uncertainty\")\n",
        "plt.legend()\n",
        "\n",
        "# Bottom plot: Zoom-in\n",
        "zoom_start, zoom_end = 180, 220\n",
        "plt.subplot(3,1,3)\n",
        "pred_zoom = np.abs(surprise_insensitive_model_results['PredictionError'][zoom_start:zoom_end+1])\n",
        "pred_zoom_norm = pred_zoom / np.max(pred_zoom)\n",
        "tau_zoom = surprise_insensitive_model_results['RelUncertainty'][zoom_start:zoom_end+1]\n",
        "tau_zoom_norm = tau_zoom / np.max(tau_zoom)\n",
        "trials_zoom = surprise_insensitive_model_results['Trial'][zoom_start:zoom_end+1]\n",
        "\n",
        "plt.plot(trials_zoom, pred_zoom_norm, color='orange', label='Surprise (Î´, normalized)')\n",
        "plt.plot(trials_zoom, tau_zoom_norm, color='purple', label='Relative Uncertainty (Ï„, normalized)')\n",
        "plt.axvspan(180, 200, color='green', alpha=0.1)\n",
        "plt.axvspan(200, 220, color='red', alpha=0.1)\n",
        "plt.ylabel(\"Normalized Values (0-1)\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.title(\"Zoom-in: Insensitivity to Surprise (Trials 180-220)\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fxa6cpLKur3p"
      },
      "source": [
        "# Flexible No. 3: Low Hazard Rate Environment"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tOQCJ7C70B6o"
      },
      "source": [
        "### ðŸ§ ðŸ§ ðŸ§  Exercise 5: Fill in the code to generate the low hazard rate model!\n",
        "<details>\n",
        "### <summary>hint:</summary>\n",
        "\n",
        "`NormativeBaseModel` Class Parameters\n",
        "\n",
        "This class simulates a learning model based on Nassar et al. (2016) and its variations. Below are the parameters used during initialization:\n",
        "\n",
        "| Parameter          | Description                                                                 | Default Value |\n",
        "| :----------------- | :-------------------------------------------------------------------------- | :------------ |\n",
        "| `X`                | Array of observed bag drop positions (trial outcomes).                      | _None_        |\n",
        "| `sigma_sequence`   | Array specifying the noise standard deviation for each trial.               | _None_        |\n",
        "| `H`                | Hazard rate, representing the prior probability of a change point.          | `0.1`         |\n",
        "| `uncertainty_scale`| Multiplier applied to predictive variance to simulate underestimation/overestimation of uncertainty. | `1.0`         |\n",
        "| `surprise_sensitivity`| Exponent applied to the likelihood in change-point probability calculation to model sensitivity to surprise. | `1.0`         |\n",
        "|\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UJtLKZPHuqwG"
      },
      "outputs": [],
      "source": [
        "low_hazard_rate_model = NormativeBaseModel(#YOUR CODE HERE)\n",
        "low_hazard_rate_model_results = low_hazard_rate_model.run()\n",
        "display(low_hazard_rate_model_results)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CMhGiedQwk2u"
      },
      "outputs": [],
      "source": [
        "plt.figure(figsize=(14,10))\n",
        "\n",
        "# Top plot: Belief vs True Helicopter\n",
        "plt.subplot(3,1,1)\n",
        "plt.plot(low_hazard_rate_model_results['Trial'], low_hazard_rate_model_results['TruePosition'], 'k--', label='True Helicopter')\n",
        "plt.plot(low_hazard_rate_model_results['Trial'], low_hazard_rate_model_results['Belief'], 'b-', label='Flexible Model Belief')\n",
        "plt.axvspan(0, 200, color='green', alpha=0.1)\n",
        "plt.axvspan(200, 400, color='red', alpha=0.1)\n",
        "plt.ylabel(\"Position (0-300)\")\n",
        "plt.title(\"Low Hazard Rate: Belief vs True Helicopter\")\n",
        "plt.legend()\n",
        "\n",
        "# Middle plot: Prediction error & relative uncertainty\n",
        "plt.subplot(3,1,2)\n",
        "plt.plot(low_hazard_rate_model_results['Trial'], low_hazard_rate_model_results['PredictionError'], color='orange', label='Surprise (Î´)')\n",
        "plt.plot(low_hazard_rate_model_results['Trial'], low_hazard_rate_model_results['RelUncertainty'], color='purple', label='Relative Uncertainty (Ï„)')\n",
        "plt.ylabel(\"Model Estimates\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.title(\"Low Hazard Rate: Surprise and Relative Uncertainty\")\n",
        "plt.legend()\n",
        "\n",
        "# Bottom plot: Zoom-in\n",
        "zoom_start, zoom_end = 180, 220\n",
        "plt.subplot(3,1,3)\n",
        "pred_zoom = np.abs(low_hazard_rate_model_results['PredictionError'][zoom_start:zoom_end+1])\n",
        "pred_zoom_norm = pred_zoom / np.max(pred_zoom)\n",
        "tau_zoom = low_hazard_rate_model_results['RelUncertainty'][zoom_start:zoom_end+1]\n",
        "tau_zoom_norm = tau_zoom / np.max(tau_zoom)\n",
        "trials_zoom = low_hazard_rate_model_results['Trial'][zoom_start:zoom_end+1]\n",
        "\n",
        "plt.plot(trials_zoom, pred_zoom_norm, color='orange', label='Surprise (Î´, normalized)')\n",
        "plt.plot(trials_zoom, tau_zoom_norm, color='purple', label='Relative Uncertainty (Ï„, normalized)')\n",
        "plt.axvspan(180, 200, color='green', alpha=0.1)\n",
        "plt.axvspan(200, 220, color='red', alpha=0.1)\n",
        "plt.ylabel(\"Normalized Values (0-1)\")\n",
        "plt.xlabel(\"Trial\")\n",
        "plt.title(\"Zoom-in: Low Hazard Rate (Trials 180-220)\")\n",
        "plt.legend()\n",
        "\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HROtynL_xrOP"
      },
      "source": [
        "# Learning Rate Trajectories Compared to the Normative Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "H82LIq5SsTjy"
      },
      "outputs": [],
      "source": [
        "all_models = [\n",
        "    normative_model_results,\n",
        "    surprise_insensitive_model_results,\n",
        "    low_hazard_rate_model_results,\n",
        "    uncertainty_underestimate_results,\n",
        "]\n",
        "\n",
        "max_pe = max(np.abs(m['PredictionError']).max() for m in all_models)\n",
        "delta_vals = np.linspace(0, max_pe, 300)  # covers full realistic range\n",
        "\n",
        "# ---- 2. Helper: sort & interpolate smoothly ----\n",
        "def sorted_interp(model, delta_vals, smooth_sigma=1):\n",
        "    \"\"\"Sorts model data by |PredictionError| before interpolation and smooths.\"\"\"\n",
        "    idx = np.argsort(np.abs(model['PredictionError']))\n",
        "    x = np.abs(model['PredictionError'].values[idx])\n",
        "    y = model['LearningRate'].values[idx]\n",
        "    # Interpolate to uniform x scale\n",
        "    interp_y = np.interp(delta_vals, x, y)\n",
        "    # Optional smoothing for visual polish\n",
        "    return gaussian_filter1d(interp_y, sigma=smooth_sigma)\n",
        "\n",
        "# ---- 3. Compute curves ----\n",
        "alpha_norm = sorted_interp(normative_model_results, delta_vals)\n",
        "alpha_surprise = sorted_interp(surprise_insensitive_model_results, delta_vals)\n",
        "alpha_hazard = sorted_interp(low_hazard_rate_model_results, delta_vals)\n",
        "alpha_uncertainty = sorted_interp(uncertainty_underestimate_results, delta_vals)\n",
        "\n",
        "# ---- 4. Styling ----\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "colors = {\n",
        "    'normative': '#c67d00',  # warm gold\n",
        "    'variant': '#26457b'     # dark blue\n",
        "}\n",
        "\n",
        "# ---- (a) Surprise insensitivity ----\n",
        "plt.subplot(1, 3, 1)\n",
        "plt.plot(delta_vals, alpha_norm, color=colors['normative'], linewidth=3, label='Normative')\n",
        "plt.plot(delta_vals, alpha_surprise, color=colors['variant'], linewidth=3, label='Surprise insensitive')\n",
        "plt.title(\"a   Surprise insensitivity\", loc='left', fontsize=12, fontweight='bold')\n",
        "plt.xlabel(\"Relative error (Î´)\")\n",
        "plt.ylabel(\"Learning rate (Î±)\")\n",
        "plt.xlim(0, max_pe)\n",
        "plt.ylim(0, 1.05)\n",
        "plt.legend(frameon=False)\n",
        "plt.tick_params(direction='out')\n",
        "plt.grid(False)\n",
        "\n",
        "# ---- (b) Low hazard rate ----\n",
        "plt.subplot(1, 3, 2)\n",
        "plt.plot(delta_vals, alpha_norm, color=colors['normative'], linewidth=3, label='Normative')\n",
        "plt.plot(delta_vals, alpha_hazard, color=colors['variant'], linewidth=3, label='Low hazard rate')\n",
        "plt.title(\"b   Low hazard rate\", loc='left', fontsize=12, fontweight='bold')\n",
        "plt.xlabel(\"Relative error (Î´)\")\n",
        "plt.xlim(0, max_pe)\n",
        "plt.ylim(0, 1.05)\n",
        "plt.legend(frameon=False)\n",
        "plt.tick_params(direction='out')\n",
        "plt.grid(False)\n",
        "\n",
        "# ---- (c) Low uncertainty ----\n",
        "plt.subplot(1, 3, 3)\n",
        "plt.plot(delta_vals, alpha_norm, color=colors['normative'], linewidth=3, label='Normative')\n",
        "plt.plot(delta_vals, alpha_uncertainty, color=colors['variant'], linewidth=3, label='Low uncertainty')\n",
        "plt.title(\"c   Low uncertainty\", loc='left', fontsize=12, fontweight='bold')\n",
        "plt.xlabel(\"Relative error (Î´)\")\n",
        "plt.xlim(0, max_pe)\n",
        "plt.ylim(0, 1.05)\n",
        "plt.legend(frameon=False)\n",
        "plt.tick_params(direction='out')\n",
        "plt.grid(False)\n",
        "\n",
        "plt.tight_layout(w_pad=2)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_3UYBfwqzEU7"
      },
      "source": [
        "## Your Turn: Background\n",
        "\n",
        "Nassar et. al. 2022 recreates this model to study the all-or-nothing belief system update observed in individuals with schizophrenia.\n",
        "\n",
        "The finding was that of pronounced reduction in moderate belief updates. They instead relied on extremes:\n",
        "\n",
        "1. Non-updates/Perseverative responses: Completely ignoring new information (learning rate near 0).\n",
        "\n",
        "2. Total updates: Completely adopting the new information (learning rate near 1)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EYtMBHpl4PZS"
      },
      "source": [
        "# A New Environment\n",
        "\n",
        "One slight modification the 2022 study made to the 2016 experiment, was an \"odd-ball condition\", which was a slight drift of the helicopter via **random walk**. This were essentially one-off outliers that didn't actually indicate a change-point occurence. Really unexpected bag locations were meant to be indicative of an odd-ball, encouraged to be ignored by participants."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EsutkZAK7rAI"
      },
      "outputs": [],
      "source": [
        "def generate_oddball_environment(n_trials=400, H_oddball=0.1, sigma=20, drift_rate=10, seed=555):\n",
        "    \"\"\"\n",
        "    Generate helicopter (true) and bag (observed) positions for oddball condition:\n",
        "    - Helicopter undergoes Gaussian random walk (gradual drift)\n",
        "    - Occasional oddball bag drops (unrelated to helicopter position)\n",
        "    - Static noise level throughout all trials\n",
        "    Hazard rate H_oddball controls probability of oddball events (not changepoints)\n",
        "    Range of positions: 0-300\n",
        "    \"\"\"\n",
        "    np.random.seed(seed)  # reproducibility\n",
        "\n",
        "    # Single static noise level for all trials\n",
        "    sigma_sequence = np.full(n_trials, sigma)\n",
        "\n",
        "    mu = np.zeros(n_trials)  # true helicopter position\n",
        "    X = np.zeros(n_trials)   # observed bag drops\n",
        "    is_oddball = np.zeros(n_trials, dtype=bool)  # track oddball trials\n",
        "\n",
        "    # Initialize helicopter in center of range\n",
        "    mu[0] = 150  # Start at center\n",
        "\n",
        "    X[0] = np.random.normal(mu[0], sigma_sequence[0])\n",
        "\n",
        "    # Generate trials\n",
        "    for t in range(1, n_trials):\n",
        "        # Helicopter undergoes random walk with reflecting boundaries\n",
        "        drift = np.random.normal(0, drift_rate)\n",
        "        proposed_position = mu[t - 1] + drift\n",
        "\n",
        "        # Reflecting boundaries: bounce back if hitting edges\n",
        "        if proposed_position < 0:\n",
        "            mu[t] = -proposed_position  # Reflect off bottom\n",
        "        elif proposed_position > 300:\n",
        "            mu[t] = 600 - proposed_position  # Reflect off top\n",
        "        else:\n",
        "            mu[t] = proposed_position\n",
        "\n",
        "        # Ensure still within bounds after reflection\n",
        "        mu[t] = np.clip(mu[t], 0, 300)\n",
        "\n",
        "        # Oddball decision: bag from random location or helicopter location?\n",
        "        if np.random.rand() < H_oddball:\n",
        "            # Oddball: bag from uniform distribution (anywhere on screen)\n",
        "            X[t] = np.random.uniform(0, 300)\n",
        "            is_oddball[t] = True\n",
        "        else:\n",
        "            # Normal: bag from helicopter location with noise\n",
        "            X[t] = np.random.normal(mu[t], sigma_sequence[t])\n",
        "\n",
        "    return mu, X, sigma_sequence, is_oddball"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_7vaYBmm75ez"
      },
      "outputs": [],
      "source": [
        "mu_oddball, X_oddball, sigma_seq_oddball, is_oddball = generate_oddball_environment()\n",
        "\n",
        "plt.figure(figsize=(12, 5))\n",
        "\n",
        "# Plot true helicopter position (random walk)\n",
        "plt.plot(mu_oddball, label='True Helicopter (Î¼) - Random Walk', linewidth=2, color='blue', alpha=0.8)\n",
        "\n",
        "# Plot normal bag drops\n",
        "normal_trials = ~is_oddball\n",
        "plt.scatter(np.where(normal_trials)[0], X_oddball[normal_trials],\n",
        "            s=15, alpha=0.6, label='Normal Bag Drops', color='gray')\n",
        "\n",
        "# Plot oddball bag drops in distinct color\n",
        "oddball_trials = is_oddball\n",
        "plt.scatter(np.where(oddball_trials)[0], X_oddball[oddball_trials],\n",
        "            s=50, alpha=0.8, label='Oddball Bag Drops', color='red', marker='x')\n",
        "\n",
        "# Add vertical dotted lines for each oddball occurrence\n",
        "for t in np.where(is_oddball)[0]:\n",
        "    plt.axvline(t, color='red', linestyle=':', alpha=0.3, linewidth=0.8)\n",
        "\n",
        "plt.title('Oddball Environment: Random Walk + Oddball Events (Ïƒ=20)')\n",
        "plt.xlabel('Trial')\n",
        "plt.ylabel('Position')\n",
        "plt.ylim(-10, 310)\n",
        "plt.legend(loc='best')\n",
        "plt.grid(True, alpha=0.3)\n",
        "plt.tight_layout()\n",
        "plt.show()\n",
        "\n",
        "# Print summary statistics\n",
        "print(f\"Total trials: {len(X_oddball)}\")\n",
        "print(f\"Oddball events: {np.sum(is_oddball)} ({100*np.mean(is_oddball):.1f}%)\")\n",
        "print(f\"Oddball trials: {np.where(is_oddball)[0][:10]}... (showing first 10)\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YZ_sXEBv_rH7"
      },
      "source": [
        "## How would we expect our normative model to learn in this environment?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AY7ZnB8A0ua4"
      },
      "source": [
        "### ðŸ§ ðŸ§ ðŸ§  Exercise 6: Fill in the code to generate the normative model in oddball environment!\n",
        "\n",
        "<details>\n",
        " <summary>hint:</summary>\n",
        "\n",
        "`NormativeBaseModel` Class Parameters\n",
        "\n",
        "This class simulates a learning model based on Nassar et al. (2016) and its variations. Below are the parameters used during initialization:\n",
        "\n",
        "| Parameter          | Description                                                                 | Default Value |\n",
        "| :----------------- | :-------------------------------------------------------------------------- | :------------ |\n",
        "| `X`                | Array of observed bag drop positions (trial outcomes).                      | _None_        |\n",
        "| `sigma_sequence`   | Array specifying the noise standard deviation for each trial.               | _None_        |\n",
        "| `H`                | Hazard rate, representing the prior probability of a change point.          | `0.1`         |\n",
        "| `uncertainty_scale`| Multiplier applied to predictive variance to simulate underestimation/overestimation of uncertainty. | `1.0`         |\n",
        "| `surprise_sensitivity`| Exponent applied to the likelihood in change-point probability calculation to model sensitivity to surprise. | `1.0`         |\n",
        "|\n",
        "</details>\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D5Q0ospJB8kO"
      },
      "outputs": [],
      "source": [
        "# REMINDER OF VARIABLES:\n",
        "\n",
        "# mu_oddball, X_oddball, sigma_seq_oddball, is_oddball = generate_oddball_environment()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I2_xqLqy_yP_"
      },
      "outputs": [],
      "source": [
        "norm_oddball = NormativeBaseModel(#YOUR CODE HERE)\n",
        "norm_oddball_results = norm_oddball.run()\n",
        "\n",
        "plt.figure(figsize=(5, 4))\n",
        "plt.plot(delta_vals, alpha_norm, color=colors['normative'], linewidth=3, label='Normative')\n",
        "plt.title(\"Normative model - Oddball\", loc='left', fontsize=12, fontweight='bold')\n",
        "plt.xlabel(\"Relative error (Î´)\")\n",
        "plt.ylabel(\"Learning rate (Î±)\")\n",
        "plt.xlim(0, max(delta_vals))\n",
        "plt.ylim(0, 1.05)\n",
        "plt.legend(frameon=False)\n",
        "plt.tick_params(direction='out')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K5VXvAol_zVo"
      },
      "source": [
        "## How MIGHT we expect older participants to learn in this environment, given our 2016 model?\n",
        "\n",
        "We have to also keep in mind that this model only contains the parameters from the 2016 model, and may miss possible factors that are captured in the 2021 model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HrbaNfQ-_8-T"
      },
      "outputs": [],
      "source": [
        "older_oddball = NormativeBaseModel(X_oddball, sigma_seq_oddball, uncertainty_scale=10, H = 0.125)\n",
        "older_oddball_results = older_oddball.run()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "collapsed": true,
        "id": "t2a_xKAxC0Ln"
      },
      "outputs": [],
      "source": [
        "max_pe = max(\n",
        "    np.abs(norm_oddball_results['PredictionError']).max(),\n",
        "    np.abs(older_oddball_results['PredictionError']).max()\n",
        ")\n",
        "delta_vals = np.linspace(0, max_pe, 300)  # smooth range\n",
        "\n",
        "def sorted_interp(model, delta_vals, smooth_sigma=1):\n",
        "    idx = np.argsort(np.abs(model['PredictionError']))\n",
        "    x = np.abs(model['PredictionError'].values[idx])\n",
        "    y = model['LearningRate'].values[idx]\n",
        "    interp_y = np.interp(delta_vals, x, y)\n",
        "    return gaussian_filter1d(interp_y, sigma=smooth_sigma)\n",
        "\n",
        "alpha_norm = sorted_interp(norm_oddball_results, delta_vals)\n",
        "alpha_flex = sorted_interp(older_oddball_results, delta_vals)\n",
        "\n",
        "colors = {\n",
        "    'normative': '#c67d00',\n",
        "    'variant': '#26457b'\n",
        "}\n",
        "\n",
        "plt.figure(figsize=(6, 4))\n",
        "plt.plot(delta_vals, alpha_norm, color=colors['normative'], linewidth=3, label='Normative')\n",
        "plt.plot(delta_vals, alpha_flex, color=colors['variant'], linewidth=3, label='Flexible')\n",
        "plt.title(\"Oddball: Normative vs Simulated Older Adults - Oddball\", loc='left', fontsize=12, fontweight='bold')\n",
        "plt.xlabel(\"Relative error (Î´)\")\n",
        "plt.ylabel(\"Learning rate (Î±)\")\n",
        "plt.xlim(0, max_pe)\n",
        "plt.ylim(0, 1.05)\n",
        "plt.legend(frameon=False)\n",
        "plt.tick_params(direction='out')\n",
        "plt.grid(False)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3dyL96b00_T9"
      },
      "source": [
        "## Sample solutions to exercise 4-6 ðŸ§ ðŸ§ ðŸ§ \n",
        "\n",
        "<details>\n",
        " <summary>Sample solutions:</summary>\n",
        "  <pre>\n",
        "  <code>\n",
        "  #4.\n",
        "  surprise_insensitive_model = NormativeBaseModel(X, sigma_seq, surprise_sensitivity=0.2)\n",
        "\n",
        "  #5.\n",
        "  low_hazard_rate_model = NormativeBaseModel(X, sigma_seq, H=0.001)\n",
        "  \n",
        "  #6.\n",
        "  norm_oddball = NormativeBaseModel(X_oddball, sigma_seq_oddball)\n",
        "  \n",
        "  </code>\n",
        "  </pre>\n",
        "</details>\n",
        "\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}